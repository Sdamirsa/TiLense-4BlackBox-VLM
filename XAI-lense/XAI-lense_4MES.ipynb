{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction to use:\n",
    "\n",
    "See this walktrhough video: https://youtu.be/uXJdhP3vyYk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths_dic={\n",
    "#     \"directory_of_images\": r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\",\n",
    "# }\n",
    "\n",
    "# desired_N_of_runs = 5\n",
    "\n",
    "# defineDic_tool={\n",
    "#     \"tool_name\": \"Mayo_endoscopic_sevirity_score\",\n",
    "#     \"tool_description\": \"Classify a colonoscopy image and provide one of the predefined assessments\",\n",
    "#     \"tool_options\":\n",
    "#         [\n",
    "#             \"normal colonoscopy image\",\n",
    "#             \"Mayo UC endoscopic score is 1 (mild)\",\n",
    "#             \"Mayo UC endoscopic score is 2 (moderate)\",\n",
    "#             \"Mayo UC endoscopic score is 3 (severe)\",\n",
    "#             \"Other abnormalities\"\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # no need to change----------------------------\n",
    "# import os\n",
    "# paths_dic[\"empty_excel_path\"] = os.path.join(paths_dic[\"directory_of_images\"], \"emptyDesign.xlsx\")\n",
    "# paths_dic[\"answered_excel_path\"] = os.path.join(paths_dic[\"directory_of_images\"], \"answered.xlsx\")\n",
    "# paths_dic[\"mask_importance\"] = os.path.join(paths_dic[\"directory_of_images\"], \"mask_importance.xlsx\")\n",
    "# paths_dic[\"mask_importance_wConNorm\"] = os.path.join(paths_dic[\"directory_of_images\"], \"mask_importance_wConNorm.xlsx\")\n",
    "\n",
    "\n",
    "# parallel_run_N = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create masked image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "def mask_tile(image, x, y, tile_width, tile_height):\n",
    "    \"\"\" Mask a specific tile in the image. \"\"\"\n",
    "    masked_image = image.copy()\n",
    "    draw = Image.new('RGBA', image.size, (0, 0, 0, 0))\n",
    "    mask = Image.new('L', (tile_width, tile_height), 0)\n",
    "    draw.paste(mask, (x, y))\n",
    "    masked_image.paste(draw, mask=draw)\n",
    "    return masked_image\n",
    "\n",
    "def blur_tile(image, x, y, tile_width, tile_height, blur_radius=20):\n",
    "    \"\"\" Blur a specific tile in the image. \"\"\"\n",
    "    blurred_image = image.copy()\n",
    "    # Extract the tile\n",
    "    tile = blurred_image.crop((x, y, x + tile_width, y + tile_height))\n",
    "    # Apply Gaussian blur to the tile\n",
    "    blurred_tile = tile.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "    # Paste the blurred tile back into the image\n",
    "    blurred_image.paste(blurred_tile, (x, y))\n",
    "    return blurred_image\n",
    "\n",
    "def process_images(folder_path, num_rows, num_cols, blur_or_mask=\"mask\", sliding=False):\n",
    "    images = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    file_name_list = []\n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        width, height = image.size\n",
    "\n",
    "        # Calculate tile dimensions (same for both static and sliding)\n",
    "        tile_width = width // num_cols\n",
    "        tile_height = height // num_rows\n",
    "\n",
    "        # Create directory for processed images\n",
    "        output_dir = os.path.join(folder_path, f\"{os.path.splitext(image_name)[0]}_{blur_or_mask}_{num_rows}x{num_cols}_{'sliding' if sliding else 'static'}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        if sliding:\n",
    "            # Generate positions for the sliding window\n",
    "            x_positions = range(0, width - tile_width + 1, tile_width // 2)\n",
    "            print(x_positions)\n",
    "            y_positions = range(0, height - tile_height + 1, tile_height // 2)\n",
    "            positions = [(x, y) for y in y_positions for x in x_positions]\n",
    "        else:\n",
    "            # Generate positions for the static grid\n",
    "            positions = [(col * tile_width, row * tile_height) \n",
    "                         for row in range(num_rows) \n",
    "                         for col in range(num_cols)]\n",
    "\n",
    "        for idx, (x, y) in enumerate(positions):\n",
    "            if blur_or_mask == \"mask\":\n",
    "                processed_image = mask_tile(image, x, y, tile_width, tile_height)\n",
    "            elif blur_or_mask == \"blur\":\n",
    "                processed_image = blur_tile(image, x, y, tile_width, tile_height)\n",
    "            else:\n",
    "                raise ValueError(\"The blur_or_mask is not correctly defined.\")\n",
    "            \n",
    "            output_image_name = f'{idx}_{x}.{x+tile_width}_{y}.{y+tile_height}_{os.path.basename(image_name)}'\n",
    "            file_name = os.path.join(output_dir, output_image_name)\n",
    "            processed_image.save(file_name)\n",
    "            file_name_list.append(output_image_name)\n",
    "\n",
    "    return file_name_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2x2 sliding mask (big sliding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# folder_path = paths_dic[\"directory_of_images\"]\n",
    "# num_rows = 2\n",
    "# num_cols = 2\n",
    "# blur_or_mask = \"mask\" # Set to \"mask\" or \"blur\"\n",
    "# sliding = True  # Set to True for sliding window, False for static grid\n",
    "# file_name_list = process_images(folder_path, num_rows, num_cols, blur_or_mask=blur_or_mask, sliding=sliding)\n",
    "# print(file_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3x3 static (small static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# folder_path = r'C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test'\n",
    "# num_rows = 3\n",
    "# num_cols = 3\n",
    "# blur_or_mask = \"blur\" # Set to \"mask\" or \"blur\"\n",
    "# sliding = False  # Set to True for sliding window, False for static grid\n",
    "# file_name_list = process_images(folder_path, num_rows, num_cols, blur_or_mask=blur_or_mask, sliding=sliding)\n",
    "# print(file_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other masks\n",
    "You can use image editors to create manual masks (for adversial attack) with masks covering the ground truth. When you are done, you can proceed with the code (it will handle the rest). Make sure that you start the folder name with the name of original image + underline + whatever you want. \n",
    "\n",
    "Here are some examples.\n",
    "https://link.springer.com/article/10.1007/s10044-021-01055-y \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an emptyDesign excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "import platform\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "\n",
    "def open_excel_file(file_path):\n",
    "    try:\n",
    "        system = platform.system()\n",
    "        if system == 'Windows':\n",
    "            os.startfile(file_path)  # Windows-specific command\n",
    "        elif system == 'Darwin':  # macOS\n",
    "            subprocess.run(['open', file_path])\n",
    "        elif system == 'Linux':\n",
    "            subprocess.run(['xdg-open', file_path])\n",
    "        else:\n",
    "            print(f\"Unsupported OS: {system}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening the file: {e}\")\n",
    "\n",
    "def show_popup_message(message):\n",
    "    # Initialize the Tkinter window (it won't be shown)\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    # Ensure the message box appears on top of other windows\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    # Show the pop-up message box\n",
    "    messagebox.showinfo(\"Information\", message)\n",
    "\n",
    "    # Destroy the Tkinter window after the message box is closed\n",
    "    root.destroy()\n",
    "\n",
    "  \n",
    "            \n",
    "def create_empty_excel(directory_path, output_excel_path, N_of_runs):\n",
    "    # Regex pattern to match the filename format\n",
    "    pattern = r'^(\\d+)_(\\d+)\\.(\\d+)_(\\d+)\\.(\\d+)_(.+)$'\n",
    "\n",
    "    # Walk through all subdirectories to find JPG files\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jpg'):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Loop through each image path and create entries for each run\n",
    "    for image_path in image_files:\n",
    "        filename = os.path.basename(image_path)\n",
    "        match = re.match(pattern, filename)\n",
    "        \n",
    "        if match:\n",
    "            idx, x1, x2, y1, y2, original_filename = match.groups()\n",
    "        else:\n",
    "            idx, x1, x2, y1, y2, original_filename = \"\", \"\", \"\", \"\", \"\", filename\n",
    "\n",
    "        for run in range(1, N_of_runs + 1):\n",
    "            data.append({\n",
    "                'image_path': image_path,\n",
    "                'run_N': run,\n",
    "                'image_idx': idx,\n",
    "                'image_X1coordinate': x1,\n",
    "                'image_X2coordinate': x2,\n",
    "                'image_Y1coordinate': y1,\n",
    "                'image_Y2coordinate': y2,\n",
    "                'original_filename': original_filename,\n",
    "                'design_model': \"gpt-4o\",\n",
    "                'design_prompt': \"\",\n",
    "                'design_tempreature': 1,\n",
    "                'design_max_completion_token': 300,\n",
    "                'design_seed' : \"\",\n",
    "                'answer_status': \"\",\n",
    "                'answer_rawResponse': \"\",\n",
    "                'answer_completiontokens': \"\",\n",
    "                'answer_prompttokens': \"\", \n",
    "                'answer_clean': \"\",\n",
    "                'correctness': \"\"\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "    \n",
    "    print(f\"Excel file created successfully: {output_excel_path}\")\n",
    "    print(f\"Total images processed: {len(image_files)}\")\n",
    "    \n",
    "    open_excel_file(output_excel_path)\n",
    "\n",
    "    show_popup_message(\"Excel file created successfully!\\nNow you should modify this file and define your model, and model parameteres.\\n\\nRemmeber that for each group of runs, you should define similiar model parameters. We will do N exactly similar runs to find the probabilities of each masked image, and use it for finding which masks are the most important ones. And by most important, we considered the most prevalent answer on the un-masked image (original), in N runs, as the base answer (and not the correct answer). If by masking an area, the answer changes, we would consider that this masked region is the most important region for the predicted class.\")  \n",
    "    \n",
    "# Example usage\n",
    "# directory_path = paths_dic[\"directory_of_images\"]\n",
    "# output_excel_path = paths_dic[\"empty_excel_path\"]\n",
    "# N_of_runs = desired_N_of_runs\n",
    " \n",
    "# create_empty_excel(directory_path, output_excel_path, N_of_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import base64\n",
    "import os\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "\n",
    "\n",
    "# Function to encode the image as base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "def set_system_message(sysmsg):\n",
    "    if sysmsg:\n",
    "        return [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": sysmsg\n",
    "        }]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def set_promptImage_message(prompt, image_path):\n",
    "\n",
    "    image_base64 = encode_image(image_path)\n",
    "    \n",
    "    promptImage_message = [\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": [\n",
    "             {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{image_base64}\"                     \n",
    "            },\n",
    "            }\n",
    "            ]}\n",
    "        ]\n",
    "    \n",
    "    return promptImage_message    \n",
    "\n",
    "def set_tool(defineDic_tool):\n",
    "    my_tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": defineDic_tool[\"tool_name\"],\n",
    "                \"description\": defineDic_tool[\"tool_description\"],\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"assessment\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": defineDic_tool[\"tool_options\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"assessment\"],\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return my_tools\n",
    "\n",
    "\n",
    "def extract_values_of_response(VLM_response):\n",
    "    try:\n",
    "        # Attempt to extract the \"assessment\" value\n",
    "        tool_call = VLM_response.choices[0].message.tool_calls[0]\n",
    "        arguments = tool_call.function.arguments\n",
    "        parsed_arguments = json.loads(arguments)\n",
    "        assessment_value = parsed_arguments.get('assessment', 'Assessment not found')\n",
    "    except (AttributeError, IndexError, json.JSONDecodeError) as e:\n",
    "        assessment_value = f\"Error extracting assessment: {e}\"\n",
    "\n",
    "    try:\n",
    "        # Attempt to extract the completion_tokens\n",
    "        completion_tokens = VLM_response.usage.completion_tokens\n",
    "    except AttributeError as e:\n",
    "        completion_tokens = f\"Error extracting completion tokens: {e}\"\n",
    "\n",
    "    try:\n",
    "        # Attempt to extract the prompt_tokens\n",
    "        prompt_tokens = VLM_response.usage.prompt_tokens\n",
    "    except AttributeError as e:\n",
    "        prompt_tokens = f\"Error extracting prompt tokens: {e}\"\n",
    "\n",
    "    # Return the results\n",
    "    return {\n",
    "        \"assessment\": assessment_value,\n",
    "        \"completion_tokens\": completion_tokens,\n",
    "        \"prompt_tokens\": prompt_tokens\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def asyncVLM_answer_wTools(idx, image_path, client, defineDic_tool, defineDic_modelParam, system_prompt=None):\n",
    "    sysmsg =set_system_message(system_prompt)\n",
    "    promptImage_message=set_promptImage_message(defineDic_modelParam['prompt'], image_path)\n",
    "    my_messages=sysmsg+promptImage_message\n",
    "    \n",
    "    my_tools= set_tool(defineDic_tool)\n",
    "    mytool_to_force={\"type\": \"function\", \"function\": {\"name\": defineDic_tool[\"tool_name\"]}} \n",
    "\n",
    "    try:\n",
    "        VLM_response = await client.chat.completions.create(\n",
    "            messages=my_messages,\n",
    "            model=defineDic_modelParam[\"model\"],\n",
    "            temperature=defineDic_modelParam[\"tempreature\"],\n",
    "            max_completion_tokens=defineDic_modelParam[\"max_completion_token\"], \n",
    "            seed = defineDic_modelParam[\"seed\"] if isinstance(defineDic_modelParam[\"seed\"],int) else None,\n",
    "            timeout=120,\n",
    "            tool_choice= mytool_to_force,\n",
    "            tools=my_tools,     \n",
    "        )\n",
    "        \n",
    "        extract_response = extract_values_of_response(VLM_response)\n",
    "        clean_class, completion_tokens, prompt_tokens  = extract_response[\"assessment\"], extract_response[\"completion_tokens\"],extract_response[\"prompt_tokens\"]\n",
    "    \n",
    "        status = \"answerGenerated\"\n",
    "        print(f'at index {idx}, clean_class is: {clean_class}')\n",
    "    except Exception as e:\n",
    "        status = f\"answerFailed: {e}\"\n",
    "        VLM_response=clean_class=completion_tokens=prompt_tokens =None\n",
    "        print(f'ERRor at index {idx}:\\n{e}')\n",
    "    finally:\n",
    "        return idx, status, VLM_response, clean_class, completion_tokens, prompt_tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defineDic_tool={\n",
    "#     \"tool_name\": \"Mayo_endoscopic_sevirity_score\",\n",
    "#     \"tool_description\": \"Classify a colonoscopy image and provide one of the predefined assessments\",\n",
    "#     \"tool_options\":\n",
    "#         [\n",
    "#             \"normal colonoscopy image\",\n",
    "#             \"Mayo UC endoscopic score is 1 (mild)\",\n",
    "#             \"Mayo UC endoscopic score is 2 (moderate)\",\n",
    "#             \"Mayo UC endoscopic score is 3 (severe)\",\n",
    "#             \"Other abnormalities\"\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# defineDic_modelParam= {\n",
    "#     \"model\":\"gpt-4o\",\n",
    "#     'prompt': \"This is a colonoscopy image. You are tasked with classifying the image for sevirity of ulcerative colitis, if present.\",\n",
    "#     \"tempreature\":1,\n",
    "#     \"max_completion_token\":300,\n",
    "#     \"seed\":123,\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #----test----------\n",
    "# idx=1\n",
    "# image_path=r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\10038-16.jpg\"\n",
    "# client = AsyncOpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "# defineDic_tool=defineDic_tool\n",
    "# defineDic_modelParam=defineDic_modelParam\n",
    "\n",
    "\n",
    "# idx, status, VLM_response, clean_class, completion_tokens, prompt_tokens  = await asyncVLM_answer_wTools(idx, image_path, client, defineDic_tool, defineDic_modelParam)\n",
    "\n",
    "# print(idx, status, VLM_response, clean_class, completion_tokens, prompt_tokens, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "\n",
    "def ask_overwrite_or_continue():\n",
    "    \"\"\"Ask the user if they want to continue with the answered Excel or overwrite it.\"\"\"\n",
    "    # Create a hidden Tkinter window\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    # Bring the window to the front\n",
    "    root.attributes('-topmost', True)\n",
    "\n",
    "    # Ask the user to continue or overwrite the file\n",
    "    result = messagebox.askyesno(\n",
    "        title=\"Continue or Overwrite\",\n",
    "        message=(\"Do you want to continue with the previously saved answered file?\"\n",
    "                 \"\\n\\nYes: Continue with the answered file.\\nNo: Overwrite and use the new design.\")\n",
    "    )\n",
    "    \n",
    "    # Close the Tkinter window\n",
    "    root.destroy()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def handle_excel_file_choice(paths_dic):\n",
    "    \"\"\"Handles the decision of using the existing answered Excel file or a new design.\"\"\"\n",
    "    if os.path.exists(paths_dic[\"answered_excel_path\"]):\n",
    "        # Ask the user if they want to continue with the previous file\n",
    "        user_choice = ask_overwrite_or_continue()\n",
    "        \n",
    "        if user_choice:  # User chose to continue with the answered file\n",
    "            df = pd.read_excel(paths_dic[\"answered_excel_path\"])\n",
    "            print(\"Continuing with the previously answered Excel file.\")\n",
    "        else:  # User chose to overwrite and use the empty Excel\n",
    "            df = pd.read_excel(paths_dic[\"empty_excel_path\"])\n",
    "            print(\"Overwriting with the new design Excel file.\")\n",
    "    else:\n",
    "        # If the answered Excel doesn't exist, use the empty one\n",
    "        df = pd.read_excel(paths_dic[\"empty_excel_path\"])\n",
    "        print(\"No previous answered file found, using the new design Excel file.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handler_asyncVLM_answer_wTools(paths_dic,defineDic_tool, parallel_run_N):\n",
    "    df = handle_excel_file_choice(paths_dic)\n",
    "    last_index = df.index[-1]\n",
    "    \n",
    "    client = AsyncOpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "    i=0\n",
    "    asyncio_tasks=[]\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            if row['answer_status'] != \"answerGenerated\":\n",
    "                defineDic_modelParam = {\n",
    "                    \"model\": row[\"design_model\"], \n",
    "                    'prompt': row[\"design_prompt\"], \n",
    "                    \"tempreature\": row[\"design_tempreature\"], \n",
    "                    \"max_completion_token\": row[\"design_max_completion_token\"], \n",
    "                    \"seed\": row[\"design_seed\"],\n",
    "                }   \n",
    "                asyncio_tasks.append(\n",
    "                    asyncVLM_answer_wTools(index, row[\"image_path\"],client, defineDic_tool, defineDic_modelParam)\n",
    "                )\n",
    "                i += 1\n",
    "                # create tasks\n",
    "                if (i<parallel_run_N) or (index == last_index and len(asyncio_tasks)>0):\n",
    "                    results = await asyncio.gather(*asyncio_tasks)\n",
    "                    for result in results:\n",
    "                        the_idx, status, VLM_response, clean_class, completion_tokens, prompt_tokens= result\n",
    "                        df.at[the_idx, \"answer_status\"] = status\n",
    "                        df.at[the_idx, \"answer_rawResponse\"] = str(VLM_response)\n",
    "                        df.at[the_idx, \"answer_completiontokens\"] = completion_tokens\n",
    "                        df.at[the_idx, \"answer_prompttokens\"] = prompt_tokens\n",
    "                        df.at[the_idx, \"answer_clean\"] = clean_class\n",
    "                    \n",
    "                    try:\n",
    "                        df.to_excel(paths_dic[\"answered_excel_path\"], index=False)\n",
    "                    except Exception as save_e:\n",
    "                        print(f\"Error in saving: {save_e}\")\n",
    "                    finally:\n",
    "                        asyncio_tasks = []\n",
    "                        i = 0  \n",
    "                        \n",
    "        except Exception as loop_e:\n",
    "            df.at[index, \"answer_status\"] = f\"Error in loop: {loop_e}\"\n",
    "        \n",
    "    return df\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths_dic={\n",
    "#     \"directory_of_images\": r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\",\n",
    "#     \"empty_excel_path\": r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\emptydesign.xlsx\",\n",
    "#     \"answered_excel_path\":  r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\answered.xlsx\",\n",
    "#     \"save_heatmaps_path\": r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\XAI_lense\"\n",
    "# }\n",
    "\n",
    "# defineDic_tool={\n",
    "#     \"tool_name\": \"Mayo_endoscopic_sevirity_score\",\n",
    "#     \"tool_description\": \"Classify a colonoscopy image and provide one of the predefined assessments\",\n",
    "#     \"tool_options\":\n",
    "#         [\n",
    "#             \"normal colonoscopy image\",\n",
    "#             \"Mayo UC endoscopic score is 1 (mild)\",\n",
    "#             \"Mayo UC endoscopic score is 2 (moderate)\",\n",
    "#             \"Mayo UC endoscopic score is 3 (severe)\",\n",
    "#             \"Other abnormalities\"\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# parallel_run_N = 10\n",
    "\n",
    "# answered_df = await handler_asyncVLM_answer_wTools(paths_dic,defineDic_tool, parallel_run_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main XAI-lense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_dic={\n",
    "    \"directory_of_images\": r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\",\n",
    "}\n",
    "\n",
    "desired_N_of_runs = 5\n",
    "\n",
    "defineDic_tool={\n",
    "    \"tool_name\": \"Mayo_endoscopic_sevirity_score\",\n",
    "    \"tool_description\": \"Classify a colonoscopy image and provide one of the predefined assessments\",\n",
    "    \"tool_options\":\n",
    "        [\n",
    "            \"normal colonoscopy image\",\n",
    "            \"Mayo UC endoscopic score is 1 (mild)\",\n",
    "            \"Mayo UC endoscopic score is 2 (moderate)\",\n",
    "            \"Mayo UC endoscopic score is 3 (severe)\",\n",
    "            \"Other abnormalities\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# no need to change the rest----------------------------\n",
    "import os\n",
    "paths_dic[\"empty_excel_path\"] = os.path.join(paths_dic[\"directory_of_images\"], \"emptyDesign.xlsx\")\n",
    "paths_dic[\"answered_excel_path\"] = os.path.join(paths_dic[\"directory_of_images\"], \"answered.xlsx\")\n",
    "paths_dic[\"mask_importance\"] = os.path.join(paths_dic[\"directory_of_images\"], \"mask_importance.xlsx\")\n",
    "paths_dic[\"mask_importance_wConNorm\"] = os.path.join(paths_dic[\"directory_of_images\"], \"mask_importance_wConNorm.xlsx\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "folder_path = paths_dic[\"directory_of_images\"]\n",
    "num_rows = 2\n",
    "num_cols = 2\n",
    "blur_or_mask = \"mask\" # Set to \"mask\" or \"blur\"\n",
    "sliding = True  # Set to True for sliding window, False for static grid\n",
    "file_name_list = process_images(folder_path, num_rows, num_cols, blur_or_mask=blur_or_mask, sliding=sliding)\n",
    "print(file_name_list)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "directory_path = paths_dic[\"directory_of_images\"]\n",
    "output_excel_path = paths_dic[\"empty_excel_path\"]\n",
    "N_of_runs = desired_N_of_runs\n",
    " \n",
    "create_empty_excel(directory_path, output_excel_path, N_of_runs)\n",
    "\n",
    "\n",
    "# This is a masked image of a colnoscopy image. You are tasked with defining the sevirity of a ulcerative colitis, if peresent. \n",
    "input(f\"Please define your desired prompt for your experiment in the prompt column of excel file saved at >>>>{output_excel_path}. >>>>> Then you can proceed with running the code. Press anything to procced .\")\n",
    "\n",
    "answered_df = await handler_asyncVLM_answer_wTools(paths_dic,defineDic_tool, parallel_run_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main XAI-attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XAI-lense heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find base answer for original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_prevalent_answers(paths_dic):\n",
    "    # Step 1: Load the Excel file\n",
    "    answered_excel_path = paths_dic[\"answered_excel_path\"]\n",
    "    df = pd.read_excel(answered_excel_path)\n",
    "\n",
    "    # Step 2: Filter rows where \"image_idx\" is NaN\n",
    "    df_filtered = df[df['image_idx'].isna()]\n",
    "\n",
    "    # Step 3: Get unique values in \"original_filename\"\n",
    "    unique_filenames = df_filtered['original_filename'].unique()\n",
    "\n",
    "    # Step 4: Create a dictionary to store results\n",
    "    result_dict = {}\n",
    "    conflicting_filenames = []\n",
    "\n",
    "    for filename in unique_filenames:\n",
    "        # Step 5: Filter rows corresponding to this \"original_filename\"\n",
    "        subset = df_filtered[df_filtered['original_filename'] == filename]\n",
    "\n",
    "        # Step 6: Find the most prevalent answer in \"answer_clean\"\n",
    "        most_common_answers = subset['answer_clean'].mode()\n",
    "\n",
    "        # Step 7: Check for conflicts (more than one prevalent answer)\n",
    "        if len(most_common_answers) == 1:\n",
    "            # Only one prevalent answer, so we store it in the dictionary\n",
    "            result_dict[filename] = most_common_answers[0]\n",
    "        else:\n",
    "            # More than one prevalent answer, so flag this filename\n",
    "            conflicting_filenames.append(filename)\n",
    "\n",
    "    # Step 8: Alert user for conflicting filenames\n",
    "    if conflicting_filenames:\n",
    "        conflict_message = f\"Conflicting prevalent answers found for filenames: {', '.join(conflicting_filenames)}. Please manually review these entries.\"\n",
    "        print(conflict_message)  # Alternatively, use logging or a UI alert\n",
    "        # Optionally, raise an exception or handle it in a way that fits your workflow\n",
    "\n",
    "    # Return the dictionary with the prevalent answers\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "# Call the function\n",
    "prevalent_answers = find_prevalent_answers(paths_dic)\n",
    "print(prevalent_answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate mask importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_mask_importance(paths_dic, prevalent_answers):\n",
    "    # Step 1: Load the Excel file\n",
    "    answered_excel_path = paths_dic[\"answered_excel_path\"]\n",
    "    df = pd.read_excel(answered_excel_path)\n",
    "\n",
    "    # Step 2: Filter rows where \"image_idx\" is not NaN (valid image_idx)\n",
    "    df_valid = df[df['image_idx'].notna()]\n",
    "\n",
    "    # Step 3: Get unique image paths\n",
    "    unique_image_paths = df_valid['image_path'].unique()\n",
    "\n",
    "    # Step 4: Initialize a dictionary to hold mask importance scores\n",
    "    mask_importance_dict = defaultdict(int)\n",
    "\n",
    "    # Step 5: Process each unique image_path\n",
    "    for image_path in unique_image_paths:\n",
    "        # Filter rows for this specific image_path\n",
    "        subset = df_valid[df_valid['image_path'] == image_path]\n",
    "        \n",
    "        # Initialize a counter for the mask importance for this image_path\n",
    "        mask_importance_score = 0\n",
    "\n",
    "        # Step 6: Compare each answer in \"answer_clean\" with the base answer\n",
    "        for _, row in subset.iterrows():\n",
    "            original_filename = row['original_filename']\n",
    "            \n",
    "            # Get the base answer from the prevalent_answers dictionary\n",
    "            base_answer = prevalent_answers.get(original_filename, None)\n",
    "            \n",
    "            if base_answer is not None:\n",
    "                # Compare with the current answer in \"answer_clean\"\n",
    "                if row['answer_clean'] != base_answer:\n",
    "                    # Add 1 point if the answers don't match\n",
    "                    mask_importance_score += 1\n",
    "\n",
    "        # Store the mask importance score for this image_path\n",
    "        mask_importance_dict[image_path] = mask_importance_score\n",
    "\n",
    "    # Step 7: Create a new DataFrame to store the result\n",
    "    mask_importance_df = df_valid.drop_duplicates(subset=['image_path']).copy()\n",
    "\n",
    "    # Step 8: Add the \"mask_importance\" column based on the computed scores\n",
    "    mask_importance_df['mask_importance'] = mask_importance_df['image_path'].map(mask_importance_dict)\n",
    "\n",
    "    # Step 9: Remove unnecessary columns (like run_N if you don't want them)\n",
    "    if 'run_N' in mask_importance_df.columns:\n",
    "        mask_importance_df = mask_importance_df.drop(columns=['run_N'])\n",
    "\n",
    "    # Step 10: Save the resulting DataFrame as an Excel file\n",
    "    output_path = paths_dic[\"mask_importance\"] \n",
    "    mask_importance_df.to_excel(output_path, index=False)\n",
    "\n",
    "    return mask_importance_df\n",
    "\n",
    "\n",
    "# Call the function\n",
    "mask_importance_df = calculate_mask_importance(paths_dic, prevalent_answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def create_heatmap_overlay(paths_dic, df,desired_N_of_runs, figure_name=\"\"):\n",
    "    # Load the original image for each unique original_filename\n",
    "    grouped = df.groupby('original_filename')\n",
    "\n",
    "    for original_filename, group in grouped:\n",
    "        # Load the original image based on the provided path\n",
    "        original_image_path = os.path.join(paths_dic[\"directory_of_images\"], original_filename)\n",
    "        original_image = Image.open(original_image_path).convert('RGBA')  # Ensure the image is RGBA\n",
    "\n",
    "        # Create a blank transparent overlay (same size as the original image)\n",
    "        overlay = Image.new('RGBA', original_image.size, (255, 255, 255, 0))  # Fully transparent overlay\n",
    "\n",
    "        # Draw importance tiles on the overlay\n",
    "        draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "        # Process each tile in the current group (filtered by coordinates presence)\n",
    "        for _, row in group.iterrows():\n",
    "            x1, y1 = int(row['image_X1coordinate']), int(row['image_Y1coordinate'])\n",
    "            x2, y2 = int(row['image_X2coordinate']), int(row['image_Y2coordinate'])\n",
    "            importance = row['mask_importance']  # Retrieve the mask importance score\n",
    "\n",
    "            normalized_importance = importance /  desired_N_of_runs\n",
    "            if importance>0:\n",
    "                # Draw a semi-transparent red rectangle on the overlay\n",
    "                draw.rectangle([x1, y1, x2, y2], fill=(255, 0, 0, int(normalized_importance * 255)))  # Transparency based on importance\n",
    "\n",
    "        # Step 7: Composite the heatmap overlay with the original image\n",
    "        result = Image.alpha_composite(original_image, overlay)\n",
    "\n",
    "        # Convert back to RGB for saving and display\n",
    "        result = result.convert('RGB')\n",
    "\n",
    "        # Step 8: Save the resulting heatmap overlay as a PNG\n",
    "        output_filename_png = f\"{original_filename}_{figure_name}.png\"\n",
    "        output_path_png = os.path.join(paths_dic[\"directory_of_images\"], output_filename_png)\n",
    "        output_filename_pdf=f\"{original_filename}_{figure_name}.png\"\n",
    "        output_path_pdf = os.path.join(paths_dic[\"directory_of_images\"], output_filename_pdf)\n",
    "        result.save(output_path_png)\n",
    "        result.save(output_path_pdf)\n",
    "\n",
    "        # Optional: Display the result\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.imshow(result)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Heatmaps have been successfully saved!\")\n",
    "\n",
    "\n",
    "# Assume df is the dataframe you have with the necessary columns\n",
    "df = pd.read_excel(paths_dic[\"mask_importance\"])\n",
    "figure_name=\"XAI-lense-heatmap\"\n",
    "create_heatmap_overlay(paths_dic, df, desired_N_of_runs=desired_N_of_runs,figure_name=figure_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XAI-lense consistency normalized heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find answer counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_answer_counts(paths_dic):\n",
    "    # Step 1: Load the Excel file\n",
    "    answered_excel_path = paths_dic[\"answered_excel_path\"]\n",
    "    df = pd.read_excel(answered_excel_path)\n",
    "\n",
    "    # Step 2: Filter rows where \"image_idx\" is NaN\n",
    "    df_filtered = df[df['image_idx'].isna()]\n",
    "\n",
    "    # Step 3: Get unique values in \"original_filename\"\n",
    "    unique_filenames = df_filtered['original_filename'].unique()\n",
    "\n",
    "    # Step 4: Create a dictionary to store the counts of each answer for each filename\n",
    "    answer_counts_dict = {}\n",
    "\n",
    "    for filename in unique_filenames:\n",
    "        # Step 5: Filter rows corresponding to this \"original_filename\"\n",
    "        subset = df_filtered[df_filtered['original_filename'] == filename]\n",
    "\n",
    "        # Step 6: Get the count of each unique answer in \"answer_clean\"\n",
    "        answer_counts = subset['answer_clean'].value_counts().to_dict()\n",
    "\n",
    "        # Step 7: Store the dictionary of answer counts in the main dictionary\n",
    "        answer_counts_dict[filename] = answer_counts\n",
    "\n",
    "    # Return the dictionary with answer counts\n",
    "    return answer_counts_dict\n",
    "\n",
    "\n",
    "# Example usage\n",
    "answer_counts = find_answer_counts(paths_dic)\n",
    "print(answer_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate mask importance with consistency normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_mask_importance_wConNorm(paths_dic, answer_counts):\n",
    "    # Step 1: Load the Excel file\n",
    "    answered_excel_path = paths_dic[\"answered_excel_path\"]\n",
    "    df = pd.read_excel(answered_excel_path)\n",
    "\n",
    "    # Step 2: Filter rows where \"image_idx\" is not NaN (valid image_idx)\n",
    "    df_valid = df[df['image_idx'].notna()]\n",
    "\n",
    "    # Step 3: Get unique image paths\n",
    "    unique_image_paths = df_valid['image_path'].unique()\n",
    "\n",
    "    # Step 4: Initialize a dictionary to hold mask importance scores\n",
    "    mask_importance_dict = defaultdict(float)\n",
    "\n",
    "    # Step 5: Process each unique image_path\n",
    "    for image_path in unique_image_paths:\n",
    "        # Filter rows for this specific image_path\n",
    "        subset = df_valid[df_valid['image_path'] == image_path]\n",
    "        \n",
    "        # Initialize a counter for the mask importance for this image_path\n",
    "        mask_importance_score = 0\n",
    "\n",
    "        # Step 6: Process each row in the subset\n",
    "        for _, row in subset.iterrows():\n",
    "            original_filename = row['original_filename']\n",
    "            answer_clean = row['answer_clean']\n",
    "            \n",
    "            # Get the answer counts for the original filename\n",
    "            if original_filename in answer_counts:\n",
    "                # Get the total number of answers for this file\n",
    "                total_answers = sum(answer_counts[original_filename].values())\n",
    "                \n",
    "                # Check if the answer is in the answer_counts dictionary\n",
    "                if answer_clean in answer_counts[original_filename]:\n",
    "                    # Calculate the score: 1 - (answer count / total answers)\n",
    "                    answer_count = answer_counts[original_filename][answer_clean]\n",
    "                    score = 1 - (answer_count / total_answers)\n",
    "                else:\n",
    "                    # If the answer is not in the dictionary, add 1\n",
    "                    score = 1\n",
    "            else:\n",
    "                # If there are no answer counts for the filename, add 1\n",
    "                score = 1\n",
    "\n",
    "            # Add the score to the mask importance score for the current image_path\n",
    "            mask_importance_score += score\n",
    "\n",
    "        # Store the mask importance score for this image_path\n",
    "        mask_importance_dict[image_path] = mask_importance_score\n",
    "\n",
    "    # Step 7: Create a new DataFrame to store the result\n",
    "    mask_importance_df = df_valid.drop_duplicates(subset=['image_path']).copy()\n",
    "\n",
    "    # Step 8: Add the \"mask_importance\" column based on the computed scores\n",
    "    mask_importance_df['mask_importance'] = mask_importance_df['image_path'].map(mask_importance_dict)\n",
    "\n",
    "    # Step 9: Remove unnecessary columns (like run_N if you don't want them)\n",
    "    if 'run_N' in mask_importance_df.columns:\n",
    "        mask_importance_df = mask_importance_df.drop(columns=['run_N'])\n",
    "\n",
    "    # Step 10: Save the resulting DataFrame as an Excel file\n",
    "    output_path = paths_dic[\"mask_importance_wConNorm\"]\n",
    "    mask_importance_df.to_excel(output_path, index=False)\n",
    "\n",
    "    return mask_importance_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "mask_importance_df = calculate_mask_importance_wConNorm(paths_dic, answer_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create ConNorm heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "# Assume df is the dataframe you have with the necessary columns\n",
    "df = pd.read_excel(paths_dic[\"mask_importance\"])\n",
    "\n",
    "\n",
    "# Assume df is the dataframe you have with the necessary columns\n",
    "df = pd.read_excel(paths_dic[\"mask_importance_wConNorm\"])\n",
    "\n",
    "figure_name=\"XAI-lense-ConNorm-heatmap\"\n",
    "create_heatmap_overlay(paths_dic, df, desired_N_of_runs=desired_N_of_runs,figure_name=figure_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Image for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = [\n",
    "    {\n",
    "    \"original_image\":r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\10010-m1-4.jpg\",\n",
    "    \"XAI_lense\": r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\10010-m1-4.jpg_XAI-lense-heatmap.png\",\n",
    "    \"XAI_lense_ConsistencyNormalized\":r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\10010-m1-4.jpg_XAI-lense-ConNorm-heatmap.png\" },\n",
    " {\n",
    "    \"original_image\":r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\10030-m1-16.jpg\",\n",
    "    \"XAI_lense\": r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\10030-m1-16.jpg_XAI-lense-heatmap.png\",\n",
    "    \"XAI_lense_ConsistencyNormalized\": r\"C:\\Users\\LEGION\\Documents\\GIT\\CMLvsLLM_onPolypImage\\DO_NOT_PUBLISH\\test\\10030-m1-16.jpg_XAI-lense-ConNorm-heatmap.png\"},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set default font and figure aesthetics for scientific standards\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Arial']\n",
    "rcParams['axes.linewidth'] = 1.5\n",
    "rcParams['axes.titleweight'] = 'bold'\n",
    "rcParams['axes.titlesize'] = 18\n",
    "\n",
    "def create_figure_for_images(figures):\n",
    "    for figure_dict in figures:\n",
    "        # Step 1: Load the images\n",
    "        original_image = mpimg.imread(figure_dict[\"original_image\"])\n",
    "        xai_lense = mpimg.imread(figure_dict[\"XAI_lense\"])\n",
    "        xai_lense_connorm = mpimg.imread(figure_dict[\"XAI_lense_ConsistencyNormalized\"])\n",
    "\n",
    "        # Step 2: Create a figure with 1 row and 3 columns\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5), constrained_layout=True)\n",
    "\n",
    "        # Step 3: Display each image in its respective column with a minimal border\n",
    "        images = [original_image, xai_lense, xai_lense_connorm]\n",
    "        titles = ['Original image', 'XAI-lense', 'XAI-lense with ConNorm']\n",
    "        \n",
    "        for ax, img, title in zip(axes, images, titles):\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(title, fontsize=16, weight='bold')\n",
    "            ax.axis('off')\n",
    "            # Add a thin border to the image\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('black')\n",
    "                spine.set_linewidth(1.5)\n",
    "\n",
    "        # Step 4: Get the original image directory and filename (without extension)\n",
    "        original_image_path = figure_dict[\"original_image\"]\n",
    "        directory, filename_with_extension = os.path.split(original_image_path)\n",
    "        filename_without_extension, _ = os.path.splitext(filename_with_extension)\n",
    "\n",
    "        # Step 5: Save the figure in the same directory with the new name\n",
    "        output_filename = f\"{filename_without_extension}_FIGURE.png\"\n",
    "        output_path = os.path.join(directory, output_filename)\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')  # Save at 300 DPI for publication quality\n",
    "        plt.close(fig)  # Close the figure after saving to avoid display issues\n",
    "\n",
    "        print(f\"Figure saved at: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "create_figure_for_images(figures)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMLvsLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
